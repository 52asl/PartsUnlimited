##DocDB; Storage and indexing of Arbitrary Data Structures##

Microsoft Azure DocumentDB is the highly-scalable NoSQL document database-as-a-service that offers rich query and transactions over schema-free data, helps deliver reliable and predictable performance, and enables rapid development.

To highlight the capability of the schema free database we will show an architectural approach to address the schema free and embrace loose typings. This will be shown through storage of the product catalog with products which contain deeply nested attributes and show an approach how they can be shown and queried across.

We also highlight common mistakes made when implementing DocumentDB and ways in which to avoid or address these.

###Setup###
For this section we assume basic knowledge of setting and consuming DocumentDB inside your application. A comprehensive guide to getting started with DocumentDB can be found [here](https://azure.microsoft.com/en-us/documentation/articles/documentdb-create-account/)

Modifications to Parts Unlimited for this section will require a DocumentDb database account created in Azure and linked to your application.
		
###Managing collections and items###

* Talk about wrap around interface to switch out SQL and DocDb

**TODO - SB - insert example interface snippet here**

####Schema free storage approach####

**TODO - SB - Get some info from Dave regarding this approach**

* Talk about Schema free storage, still need to define a schema someplace to use (Whether it’s in the Application or UI layer )
	* Talk about option of storing schema against DB

####Collection partitioning strategy####
	
Collections act as highly available data partitions for document storage and processing. A common practice when migratign from a SQL database implementation to DocumentDB is to define an individual DocumentDB collection per table or item type. It is however important to remember that a collection within DocumentDB can store items with a diverse range of content and potential schemas. Additionally, Azure DocumentDB pricing is based on a "per collection" model, with larger amounts fo collections incurring higer costs. It is therefore reccomended to have a collection strategy that minimises the amount of total collections and viewing collections as partitions of data rather than tables, thus having these collections driven by capacity requirements (individual collection have a 10GB cap), or by throughput requirements for the individual collection based on the data housed within, as individual collections can be assigned different performance tiers (see the throttling section below).

Different "types" of items can be stored within an individual collection by creating a "type" discriminator property for each entry within the collection to enable filtering by item type. e.g.

	SELECT * FROM c WHERE c.type = "Product"
	
**TODO - SB - expand on performance benefits of less collections

###Querying DocumentDB###
	
####Complex arbitraty JSON documents####

* Allow users to see a BoM (bill of materials) type structure and to search for similar items deep within that structure where search relies on indexed arbitrary structure
	* In particular we need to show the power of being able to perform a fast, strongly typed query, on arbitraty data structures
	* Call out the indexing options
	* Something where it matters to be numeric, and it matters to be a string, To show that it's not just Full Text Indexing, and we want to be deeply nested

* Search for related products with SQL like query

####Caching query objects####

A common mistake is to create a new DocumentClient each time the application intends to perform a reuqest to DocumentDB. Each DocumentClient instance is thread-safe and performs efficient connection management and address caching when operating in Direct Mode. Therefore, creating a new instance of DocumentClient is an expensive operation that can have performance implications. To allow efficient connection management and better performance by DocumentClient, it is recommended to use a single instance of DocumentClient per AppDomain for the lifetime of the application.

In Azure DocumentDB, each document has a system-generated selfLink. These selfLinks are guaranteed to be unique and immutable for the lifetime of the document, and reading a single document using a selfLink is commonly referenced as the most effecient way to consume a single document. It is important to note however, that a common mistake is to create new instances of 'GetOrCreateDatabase' or 'GetOrCreateCollection' every time a reference to a database or collection is needed in order to retrieve SelfLinks. This results in mutliple queries to DocumentDB for every single intended operation, and can result in exceeding your request quota and getting throttled. It is therefore reccommended ot cahce these objects whenever suitable if they are required by the application.

It is important ot note that today, we can do away with SelfLinks to a large degree, avoiding this issue entirely. a UriFactory can be used to construct links that are based on the ID property of items, and therefore a query for databases or collections are not needed in many cases.

**TODO - SB - Insert sample of URI builder with ID bases routing **
		
####Managing throttling####

Azure DocumentDB implements a reserved throughput model for each individual collection that resides in your database account. Throughput requirements can be managed for individual collections as requirements from the application change by settign their respective performance levels, which can be viewed [here](https://azure.microsoft.com/en-us/documentation/articles/documentdb-performance-levels/)

As a result of throughput throttling on individual collections, it is possible to observe confusing behaviour inside your application as certain requests to DocumentDb succeed and others fail once they have exceeded their individual request quota and get throttled. Itsi therefore important to account for this behavior within your application.

When the application exceeds the allowed throughput for the collection, DocumentDB will preemptively ends the request and respond with HTTp status code 429 (Request too large), and return a "x-ms-retry-after-ms header representing the amount of time (in milliseconds) that the application must wait before attempting another request:

	HTTP Status 429,
	Status Line: RequestRateTooLarge
	x-ms-retry-after-ms :100
	
When using the DocumentDB .Net SDK with LINQ, the SDK will automatically retry the failed operation internally when it encounters an HTTP 429. There are however scenarios where default throttling exception behavior from the SDK may not be sufficient, and in such cases the application can be modified to handle the RequestRateTooLargeException. An example of dealing with the exception can be found below:
	
	TimeSpan delayTime = TimeSpan.Zero;
	
	try
	{
		return await func();
	}
	catch (DocumentClientException clientException)
	{
		if ((int)clientException.StatusCode != 429)
		{
			throw;
		}
		delayTime = exception.RetryAfter;
	}
	catch (AggregateException aggregateException)
	{
		if (!(aggregateException.InnerException is DocumentClientException))
		{
			throw;
		}

		DocumentClientException clientException = (DocumentClientException)aggregateException.InnerException;
		if ((int)clientException.StatusCode != 429)
		{
			throw;
		}
		delayTime = clientException.RetryAfter;
	}

	await Task.Delay(delayTime);

**TODO - SB - reference fault handling stuff (same as Redis ??)**

####Comparison of typed queries vs JSON to client####

**TODO - SB - Expand on this after chat with Dave**

* Compare Typed query VS Json document to client
	* JSON direct to client exists currently. 
	* When a document is retrieved, the internal deserialization process is not triggered untill a property of the document is accessed. e.g. var id = Document.Id.  
	* However, if  a JsonWriter i sused on the document object to get the string, the deserialization overhead is skipped.
	* Additionally, you load from string directly instead of again deserializing string to object and then us doing object to string process again. Resource.LoadFrom does this currently.

###Parts Unlimited updates###

* Re work product storage to utilize DOC DB
* Store something other than products ?? - To show multiple collections VS table
* Search for related products with SQL like query
	* Include Manufacturer, model, **year number**, country origin. Search for products with same and year +/- 3 years as they are similar.
	* Display all products – top 10 – Ryan call out.
