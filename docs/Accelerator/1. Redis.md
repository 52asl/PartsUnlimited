##Scaling Redis##

Redis is a technology used to cache items from within your application, this making resource hungry requests less often and improving the read performance.

Azure Redis Cache is based on the open-source Redis cache. It gives you access to a secure, dedicated Redis cache, managed by Microsoft and accessible from any application within Azure. 

This section will see us reviewing common pitfalls with connection management, identifying an approach to keeping the items in our cache up to date. We'll also look at what happens when the cache is failing over to a secondary or is offline how we detecting these failure conditions and ensure our application is resilient at failure time.

We will mention Sharding within the premium tier, other types of data retrieval within Redis (Sets, query, sort, pub sub) and Cache providers which can plug into your application with minimal code changes.

###Setup###

**TODO-DS** :Expand... Tiers in Azure, what they are for and how they are different.

1. basic single node no replication, go down see No resiliancy.
2. standard : two nodes, dedicated hardware, no throttling up to machine specs, update second tier, in memory replication, automated switching fail over bethe scenes.
3. premium : sharding, percistance to disk

###Cache options###

Redis is a quick access in memory data store, because of this there are several applications of how Redis can be integrated into your application. Including some which plug into existing ASP.NET extensibility points.

* Output cache - [Azure Redis ASP.Net Output cache provider](https://azure.microsoft.com/en-us/documentation/articles/cache-asp.net-output-cache-provider/)
* Session state - [Azure Redis Session State provider](https://azure.microsoft.com/en-us/documentation/articles/cache-asp.net-session-state-provider/)

The rest of this example will look at using Redis within our application layer to store frequently accessed application data.

###Client Libraries###

There are multiple client libraries across several languages. Each library can be used to connect into Redis servers. Because Parts unlimited is an ASP.NET application this example will use a C# library. The two most common and recommended by Redis.io client libraries for c# are ServiceStack.Redis and StackExchange.Redis.  For this example we have chosen to use StackExchange.Redis. 

See [here](http://redis.io/clients) for an up to date list of client libraries which support Redis.

> With all external dependencies it's good practice to wrap the behavior behind an interface. This adheres to one of the Gang of Four design techniques - Program to an 'interface', not an 'implementation'. This will enable us to switch out the implementation of the cache with another implementation at run time with out having to worry about where the cache is used. See SetupCache method in the [Startup.cs](..\..\src\PartsUnlimitedWebsite\Startup.cs) class where we switch between a in memory cache and Redis cache. 

###Connection###

The first thing which is required is to setup a connection to the Redis cache which has been configured within Azure. The StackExchange.Redis client uses multiplexing through a single connection. The recommended usage is to create a single instance of the client and use this instance for all further commands issued to the cache. See the Parts Unlimited implementation of the connection [here](..\..\src\PartsUnlimitedWebsite\Cache\PartsUnlimitedRedisCache.cs) 

    private static Lazy<ConnectionMultiplexer> lazyConnection = new Lazy<ConnectionMultiplexer>(() =>
    {
        return ConnectionMultiplexer.Connect(configurationOptions);
    });

    public static ConnectionMultiplexer Connection
    {
        get { return lazyConnection.Value; } 
    }

> Because StackExchange.Redis uses multiplexing we should re-use the same instance of the ConnectionMultiplexer across the application. If you are wrapping up the Redis logic in one class ensure that this class is a singleton. Modern dependency injection frameworks have a way to achieve this.     

###Retry / Failure###

As experienced developers we know transient errors occur and if not managed correctly will manifest into a poor experience for users of the application. 
To make our applications as robust and resilient as possible we need to consider patterns to reduce the impact of these transient errors. 

**TODO-DS** : Redis Failover dialog and link - Explain the failure scenario E.g. Redis slave / failover and opportunity for down time while failover in progress.. Only if secondary exists (Tie back to the tiers)

####Minimising impact####

The StackExchange.Redis client has connection management retry logic built in to the libraries. Unfortunately this retry logic is only supported when establishing the initial connection to the cache and does not apply to operations and commands against the cache once the initial connection has been made. The retry logic also does not have a configurable delay between retry attempts, simply it retries connecting after the connection timeout expires for the specified number of retries.

We want to have more control with our retry logic and also be able to apply this logic to more operations than just our initial connection. Because of this we will make use of the [Transient fault handling application block](https://msdn.microsoft.com/en-us/library/dn440719.aspx). This application block has built in support for common storage mechanims out of the box (Azure SQL, Azure Service Bus, Azure Storage). 

Unfortunately there is no direct support for Redis Cache in the application however we can customize the behavior to understand whether an error is transient. This is achieved through the use of the ITransientErrorDetectionStrategy.  This interface defines the behavior which must be implemented by custom components responsible for detecting specific transient conditions.

    public interface ITransientErrorDetectionStrategy
    { 
        bool IsTransient(Exception ex);
    }

This interface allows a custom transient error detection strategy. This determines whether the specified exception  which occurs represents a transient failure that will be compensated by a retry by the framework.

Parts Unlimited implementation of this interface is [RedisTransientErrorDetectionStrategy.cs](..\..\src\PartsUnlimitedWebsite\Cache\RedisTransientErrorDetectionStrategy.cs). 

> Notice that we interrogate the internals of the RedisConnectionException to determine if it's a connection error which should be retried. This is based on the ConnectionFailureType.FailureType, otherwise if it's a timeout we will retry.

To combine the RedisTransientErrorDetectionStrategy and the Transient framework together see the implementation of [TransientRedisCacheWrapper](..\..\src\PartsUnlimitedWebsite\Cache\TransientRedisCacheWrapper.cs).

    var fixedRetryStrategy = new FixedInterval(3, TimeSpan.FromSeconds(1));
    _retryPolicy = new RetryPolicy<RedisTransientErrorDetectionStrategy>(fixedRetryStrategy);

This is where we identify the retry strategy (FixedInterval) with the custom error detection strategy (RedisTransientErrorDetectionStrategy). Here you can see we have opted for a fixed interval retry strategy. Alternatively we could use 'ExponentialBackoff' or 'Incremental' retry strategies. 
 
####Failure alternatives####

In the case where we have sustained transient errors which re occur after the scheduled retries OR non transient errors  we need to ensure that our application is resilient when we cannot reach the underlying cache. We need to make a decision as to whether we redirect traffic to the source system or we notify the user that an error has occurred. Perhaps depending on the level of impact on your application or business would determine the decision here.

> If you relied on reading from the cache as part of the ordering process in an e-commerce store and this failed, this could be a candidate to read from the underlying data store. Comparing this to a failure to read from the cache for display purposes, this would be less sever and perhaps acceptable to direct the user to an error page.

####Cache Invalidation####

When items are put into a cache we generally specify a TTL (time to live) and whether this is a sliding or fixed period.

Say we are caching a product category which has a TTL of 10 minutes. 
After the 10 minutes expires Redis will evict this product category on our behalf. The next user who makes the same request will cause a cache miss, and will trigger a load from the source system to load the underlying record, push this into Redis and then return the category for the application. 

Ideally we would take the load time from the underlying data source away from the user to ensure they receive predictable performance.
An approach to use here is to pre-load the cache in an out of proc process, this will not impact the user and ensure that the records in the cache are hot for end users to read.
	 
> Consider a webjob. This would be responsible for loading items from the underlying source system, updating the cache with the new version.

Within the Azure portal you can review the cache misses vs cache hits. You could use this to validate your TTL settings and also what items are candidate for a automated regular refresh. 

####Cache Storage####

**TODO** : Determine what is talked about VS what is shown.
Can be a KVP, lesser known features sets, sorting and pub sub abilities. Call out to Signal R Back plane ?


###Parts Unlimited updates###

* wrap cache access behind interface
* intorduce redis cache
* configure singleton connection managment
* allow using of mem cache if nor redis connection in config
* introduce results in tasks for async
* Transient error handling
* Direct 1 or 2 cache items back to source system otherwise direct to error page

